"""
FastAPI server z poprawionym loggingiem
"""
from fastapi import FastAPI, BackgroundTasks, HTTPException
from pydantic import BaseModel
import subprocess
import logging
import asyncio
from typing import Optional
import os
import sys

# Konfiguracja logowania
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler('/app/analysis.log')
    ]
)
logger = logging.getLogger(__name__)

app = FastAPI(title="Stock Analysis API", version="1.0.0")

class AnalysisRequest(BaseModel):
    ticker: str
    trends: str
    start_date: str
    test_size_pct: float = 0.15
    forecast_days: int = 20

class AnalysisResponse(BaseModel):
    success: bool
    message: str
    task_id: Optional[str] = None

# SÅ‚ownik do Å›ledzenia aktywnych zadaÅ„
active_tasks = {}

@app.get("/")
async def root():
    return {"message": "Stock Analysis API is running"}

@app.get("/health")
async def health_check():
    return {"status": "healthy", "service": "stock-analysis"}

@app.post("/analyze", response_model=AnalysisResponse)
async def run_analysis(request: AnalysisRequest, background_tasks: BackgroundTasks):
    """
    Uruchom analizÄ™ gieÅ‚dowÄ… w tle
    """
    try:
        # Walidacja parametrÃ³w
        if request.test_size_pct < 0.05 or request.test_size_pct > 0.5:
            raise HTTPException(
                status_code=400,
                detail="test_size_pct musi byÄ‡ miÄ™dzy 0.05 a 0.5"
            )

        if request.forecast_days < 1 or request.forecast_days > 90:
            raise HTTPException(
                status_code=400,
                detail="forecast_days musi byÄ‡ miÄ™dzy 1 a 90"
            )

        # Generuj ID zadania
        task_id = f"{request.ticker}_{int(asyncio.get_event_loop().time())}"

        logger.info(f"ğŸš€ Tworzenie nowego zadania: {task_id}")
        logger.info(f"ğŸ“Š Parametry: ticker={request.ticker}, start={request.start_date}, test_pct={request.test_size_pct}, forecast={request.forecast_days}")

        # Dodaj zadanie do Å›ledzenia
        active_tasks[task_id] = {
            "status": "running",
            "parameters": request.dict(),
            "logs": []
        }

        # Uruchom analizÄ™ w tle
        background_tasks.add_task(
            run_analysis_task,
            task_id,
            request.ticker,
            request.trends,
            request.start_date,
            request.test_size_pct,
            request.forecast_days
        )

        return AnalysisResponse(
            success=True,
            message=f"Analiza dla {request.ticker} zostaÅ‚a uruchomiona w tle",
            task_id=task_id
        )

    except Exception as e:
        logger.error(f"âŒ BÅ‚Ä…d podczas uruchamiania analizy: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/analyze/{task_id}")
async def get_analysis_status(task_id: str):
    """
    SprawdÅº status zadania analizy
    """
    if task_id not in active_tasks:
        raise HTTPException(status_code=404, detail="Zadanie nie znalezione")

    return active_tasks[task_id]

@app.get("/analyze/{task_id}/logs")
async def get_analysis_logs(task_id: str):
    """
    Pobierz logi zadania analizy
    """
    if task_id not in active_tasks:
        raise HTTPException(status_code=404, detail="Zadanie nie znalezione")

    return {
        "task_id": task_id,
        "logs": active_tasks[task_id].get("logs", []),
        "status": active_tasks[task_id].get("status", "unknown")
    }

@app.post("/analyze/sync", response_model=AnalysisResponse)
async def run_analysis_sync(request: AnalysisRequest):
    """
    Uruchom analizÄ™ synchronicznie (moÅ¼e trwaÄ‡ dÅ‚ugo)
    """
    try:
        logger.info(f"ğŸ”„ Synchroniczne uruchomienie analizy dla {request.ticker}")

        # Uruchom analizÄ™ bezpoÅ›rednio
        result = await run_analysis_subprocess(
            request.ticker,
            request.trends,
            request.start_date,
            request.test_size_pct,
            request.forecast_days
        )

        if result["success"]:
            logger.info(f"âœ… Synchroniczna analiza zakoÅ„czona pomyÅ›lnie dla {request.ticker}")
            return AnalysisResponse(
                success=True,
                message=f"Analiza dla {request.ticker} zakoÅ„czona pomyÅ›lnie"
            )
        else:
            logger.error(f"âŒ Synchroniczna analiza nieudana dla {request.ticker}: {result['error']}")
            raise HTTPException(
                status_code=500,
                detail=f"BÅ‚Ä…d analizy: {result['error']}"
            )

    except Exception as e:
        logger.error(f"âŒ BÅ‚Ä…d podczas synchronicznej analizy: {e}")
        raise HTTPException(status_code=500, detail=str(e))

async def run_analysis_task(task_id: str, ticker: str, trends: str, start_date: str, test_size_pct: float, forecast_days: int):
    """
    Zadanie w tle do uruchomienia analizy
    """
    try:
        logger.info(f"ğŸ¯ RozpoczÄ™cie analizy {task_id} dla {ticker}")

        # Aktualizuj status
        active_tasks[task_id]["status"] = "running"
        active_tasks[task_id]["start_time"] = asyncio.get_event_loop().time()
        active_tasks[task_id]["logs"].append(f"RozpoczÄ™cie analizy dla {ticker}")

        # Uruchom analizÄ™
        result = await run_analysis_subprocess(ticker, trends, start_date, test_size_pct, forecast_days)

        # Aktualizuj status koÅ„cowy
        active_tasks[task_id]["status"] = "completed" if result["success"] else "failed"
        active_tasks[task_id]["end_time"] = asyncio.get_event_loop().time()
        active_tasks[task_id]["result"] = result

        # Dodaj logi z subprocess do zadania
        if "output" in result:
            active_tasks[task_id]["logs"].extend(result["output"].split('\n'))

        logger.info(f"ğŸ Analiza {task_id} zakoÅ„czona: {result['success']}")

    except Exception as e:
        logger.error(f"ğŸ’¥ BÅ‚Ä…d w zadaniu {task_id}: {e}")
        active_tasks[task_id]["status"] = "failed"
        active_tasks[task_id]["error"] = str(e)
        active_tasks[task_id]["logs"].append(f"BÅÄ„D: {str(e)}")

async def run_analysis_subprocess(ticker: str, trends: str, start_date: str, test_size_pct: float, forecast_days: int):
    """
    Uruchom skrypt analizy jako subprocess z lepszym loggingiem
    """
    try:
        logger.info(f"ğŸ”§ Przygotowywanie subprocess dla {ticker}")

        # Przygotuj komendÄ™
        cmd = [
            "python", "/app/stock_model.py",
            "--ticker", ticker,
            "--trends", trends,
            "--start_date", start_date,
            "--test_size_pct", str(test_size_pct),
            "--forecast_days", str(forecast_days)
        ]

        logger.info(f"ğŸ“ Komenda: {' '.join(cmd)}")

        # Uruchom subprocess z przekierowaniem stdout/stderr
        process = await asyncio.create_subprocess_exec(
            *cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.STDOUT,  # Przekieruj stderr do stdout
            cwd="/app",
            env={**os.environ, "PYTHONUNBUFFERED": "1"}  # WymuÅ› unbuffered output
        )

        logger.info(f"ğŸš€ Subprocess uruchomiony z PID: {process.pid}")

        # Czytaj output w czasie rzeczywistym
        output_lines = []
        while True:
            try:
                line = await asyncio.wait_for(process.stdout.readline(), timeout=1.0)
                if not line:
                    break

                line_str = line.decode().strip()
                if line_str:
                    output_lines.append(line_str)
                    logger.info(f"ğŸ“„ [{ticker}] {line_str}")

            except asyncio.TimeoutError:
                # SprawdÅº czy proces jeszcze dziaÅ‚a
                if process.returncode is not None:
                    break
                continue

        # Czekaj na zakoÅ„czenie procesu
        await process.wait()

        full_output = '\n'.join(output_lines)

        logger.info(f"ğŸ”š Subprocess zakoÅ„czony z kodem: {process.returncode}")

        # SprawdÅº kod wyjÅ›cia
        if process.returncode == 0:
            logger.info(f"âœ… Analiza {ticker} zakoÅ„czona pomyÅ›lnie")
            return {
                "success": True,
                "output": full_output,
                "ticker": ticker,
                "return_code": process.returncode
            }
        else:
            logger.error(f"âŒ Analiza {ticker} zakoÅ„czona z bÅ‚Ä™dem (kod: {process.returncode})")
            return {
                "success": False,
                "error": f"Process exited with code {process.returncode}",
                "output": full_output,
                "ticker": ticker,
                "return_code": process.returncode
            }

    except asyncio.TimeoutError:
        logger.error(f"â° Timeout analizy dla {ticker}")
        return {
            "success": False,
            "error": "Analiza przekroczyÅ‚a limit czasu (10 minut)",
            "ticker": ticker
        }
    except Exception as e:
        logger.error(f"ğŸ’¥ WyjÄ…tek podczas analizy {ticker}: {e}")
        return {
            "success": False,
            "error": str(e),
            "ticker": ticker
        }

if __name__ == "__main__":
    import uvicorn
    logger.info("ğŸŒŸ Uruchamianie FastAPI server")
    uvicorn.run(
        "app:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
